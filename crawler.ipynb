{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google 商家評論爬蟲\n",
    "\n",
    "Github 連結: https://github.com/TimLai666/google-maps-store-review-crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安裝套件\n",
    "\n",
    "1. 非 Colab 環境:\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "2. Colab 環境:<br/>\n",
    "    執行下方程式碼⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 requests pandas emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主要程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from IPython.display import display_html\n",
    "import requests\n",
    "import json\n",
    "import emoji\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "class GoogleMapsReviewCrawler:\n",
    "    def __init__(self):\n",
    "        self.__config_url__ =\"https://raw.githubusercontent.com/TimLai666/google-maps-store-review-crawler/refs/heads/main/crawler_config.json\"\n",
    "        res = requests.get(self.__config_url__)\n",
    "        config = res.json()\n",
    "        self.headers = config.get(\"headers\")\n",
    "        self.store_id_url = config.get(\"storeSearchUrl\")\n",
    "        self.store_name_url = config.get(\"storeNameUrl\")\n",
    "        self.review_url = config.get(\"reviewUrl\")\n",
    "        \n",
    "    def get_store_id(self, store_name: str):\n",
    "        '''store_name 必須與 google 地圖搜尋結果完全一致, 例如: 隱家拉麵 士林店'''\n",
    "        url = self.store_id_url.format(store_name=store_name)\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        pattern = r'0x.{16}:0x.{16}'\n",
    "        match = re.search(pattern, str(soup))\n",
    "        store_id = match.group()\n",
    "        \n",
    "        return store_id\n",
    "\n",
    "    def get_store_name(self, store_id: str):\n",
    "        url = self.store_name_url.format(store_id=store_id)\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        meta_list=soup.find_all('meta')\n",
    "        if len(meta_list) == 0:\n",
    "            raise Exception('無法取得商家資料')\n",
    "        store_name=[]\n",
    "        for i in meta_list:\n",
    "            if '''itemprop=\"name\"''' in str(i):\n",
    "                matched = re.search('\".*·',str(i))\n",
    "                if not matched:\n",
    "                    raise Exception('無法取得商家資料')\n",
    "                store_name.append(matched.group()[1:-2])\n",
    "        store_name=store_name[0]\n",
    "\n",
    "        return store_name\n",
    "\n",
    "    \n",
    "    def get_related_store_names(self, store_name):\n",
    "        '''輸入店名，返回與搜尋最相關的店名與id'''\n",
    "        url = self.store_id_url.format(store_name=store_name)\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        soup = BeautifulSoup(response.text, \"lxml\")\n",
    "        pattern = r'0x.{16}:0x.{16}'\n",
    "        store_id_list = set(re.findall(pattern, str(soup)))\n",
    "        store_id_list = [store_id.replace('\\\\', '') for store_id in store_id_list]\n",
    "        store_name_list = []\n",
    "        for store_id in store_id_list:\n",
    "            try:\n",
    "                store_name_list.append(self.get_store_name(store_id))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        store_dict = {index: letter for index,\n",
    "                    letter in zip(store_name_list, store_id_list)}\n",
    "\n",
    "        return store_dict\n",
    "    \n",
    "    def get_review(self, store_id: str, page_count=1, sorted_by=2, max_waiting_interval=5):\n",
    "        '''\n",
    "        page_count 參數對應：\n",
    "            0 - 抓取所有評論\n",
    "            n - 抓取 n 頁評論\n",
    "        \n",
    "        sorted_by 參數對應：\n",
    "            1 - 最相關 (Most Relevant)\n",
    "            2 - 最新 (Newest)\n",
    "            3 - 評分最高 (Highest Rating)\n",
    "            4 - 評分最低 (Lowest Rating)\n",
    "        \n",
    "        每個 page 會有10筆資料，除非評論數未達10筆\n",
    "        '''\n",
    "        next_token = \"\"\n",
    "        commont_list = []\n",
    "        page = 1\n",
    "        while page_count == 0 or page <= page_count:\n",
    "            # 每頁抓取間隔時間\n",
    "            interval_time = random.randint(1, max_waiting_interval)\n",
    "            print(f\"第 {page} 頁開始抓取\")\n",
    "            \n",
    "            params = {\n",
    "                \"authuser\": \"0\",\n",
    "                \"hl\": \"zh-TW\",\n",
    "                \"gl\": \"tw\",\n",
    "                \"pb\": (\n",
    "                    f\"!1m6!1s{store_id}!6m4!4m1!1e1!4m1!1e3!2m2!1i10!2s\"\n",
    "                    f\"{next_token}\"\n",
    "                    f\"!5m2!1s0OBwZ4OnGsrM1e8PxIjW6AI!7e81!8m5!1b1!2b1!3b1!5b1!7b1!11m0!13m1!1e{sorted_by}\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "            response = requests.get(self.review_url, params=params, headers=self.headers)\n",
    "            data = json.loads(emoji.demojize(response.text[4:]))\n",
    "            print(f\"第 {page} 抓取結束\")\n",
    "            \n",
    "            if not data:\n",
    "                print(f\"沒有任何評論，結束抓取\")\n",
    "                break\n",
    "\n",
    "            next_token = data[1]\n",
    "            commont_list.extend(data[2])\n",
    "            if not next_token or page == page_count:\n",
    "                print(f\"所有評論已抓取完成，總共抓取 {len(commont_list)} 則評論\")\n",
    "                break\n",
    "            \n",
    "            # 等待間隔時間，避免被 google 封鎖\n",
    "            print(f\"等待 {interval_time} 秒後抓取下一頁\")\n",
    "            time.sleep(interval_time)\n",
    "            page += 1\n",
    "            \n",
    "        # 提取需要的資料\n",
    "        commont_dict_list = []\n",
    "        for review_data in commont_list:\n",
    "            \n",
    "            try:\n",
    "                review_date = review_data[0][2][2][0][1][21][6][-1]\n",
    "                review_date = datetime(review_date[0], review_date[1], review_date[2], review_date[3]).strftime('%Y/%m/%d %H:%M:%S')\n",
    "            except:\n",
    "                review_date = None\n",
    "\n",
    "            try:\n",
    "                review_text = review_data[0][2][-1][0][0]\n",
    "            except:\n",
    "                review_text = None\n",
    "\n",
    "            review_info = {\n",
    "                \"評論者\": review_data[0][1][4][5][0],\n",
    "                \"評論者id\": review_data[0][0],\n",
    "                \"評論者狀態\": review_data[0][1][4][5][10][0],\n",
    "                \"評論者等級\": review_data[0][1][4][5][9],\n",
    "                \"留言時間\": review_data[0][1][6],\n",
    "                \"留言日期\": review_date,\n",
    "                \"評論\": review_text,\n",
    "                \"評論分數\": review_data[0][2][0][0]\n",
    "            }\n",
    "            commont_dict_list.append(review_info)\n",
    "\n",
    "        return commont_dict_list\n",
    "    \n",
    "    def display_table(self, reviews):\n",
    "        df = pd.DataFrame(reviews)\n",
    "        display_html(df)\n",
    "\n",
    "    def save_reviews_to_csv(self, reviews, filename):\n",
    "        df = pd.DataFrame(reviews)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"評論已儲存至 {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gmcc = GoogleMapsReviewCrawler()\n",
    "    store_id, store_name = \"\", \"\"\n",
    "    while True:\n",
    "        store_name_input = input(\"請輸入店名: \")\n",
    "        if not store_name_input:\n",
    "            print(\"店名不得為空，請重新輸入店名\")\n",
    "            continue\n",
    "    \n",
    "        store_dict = gmcc.get_related_store_names(store_name_input)\n",
    "        print(store_dict)\n",
    "        for name, id in store_dict.items():\n",
    "            is_correct = input(f\"是否為您要找的店? [ {name} ] (y/n): \").lower() == 'y'\n",
    "            if is_correct:\n",
    "                store_name, store_id = name, id\n",
    "                break\n",
    "        if not store_id:\n",
    "            print(\"沒有更多商家資料，請重新輸入店名\")\n",
    "        break\n",
    "    \n",
    "    print(f\"完整店名: {store_name}\")\n",
    "    page_count = int(input(\"輸入要爬取的頁數，輸入0則爬取所有評論: \"))\n",
    "    commont_dict_list = gmcc.get_review(store_id=store_id, page_count=page_count, sorted_by=2)\n",
    "    print(commont_dict_list)\n",
    "    \n",
    "    gmcc.display_table(commont_dict_list)\n",
    "    \n",
    "    does_save_to_csv = input(\"是否要儲存評論至 CSV 檔? (y/n): \").lower() == 'y'\n",
    "    while does_save_to_csv:\n",
    "        csv_filepath = input(\"輸入 CSV 路徑: \")\n",
    "        try:\n",
    "            gmcc.save_reviews_to_csv(commont_dict_list, csv_filepath)\n",
    "            break\n",
    "        except:\n",
    "            print(\"輸入錯誤，請重新輸入CSV 路徑\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
